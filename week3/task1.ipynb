{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1: Get detections from Mask R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on this [official demo](https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/demo/Mask_R-CNN_demo.ipynb) and it can be run in a docker container powered with Jupyter. \n",
    "\n",
    "A Dockerfile can be found in the [official repository](https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/docker/docker-jupyter/Dockerfile) but it needs to be modified to fix an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Instructions\n",
    "\n",
    "1. Add the following line at the end of the Dockerfile:\n",
    "    \n",
    "    `RUN pip install requests`\n",
    "    \n",
    "1. Build image with:\n",
    "\n",
    "     `docker build -t my-maskrcnn-benchmark-jupyter --build-arg CUDA=10.0 --build-arg CUDNN=7 docker/docker-jupyter/`\n",
    "\n",
    "1. Copy your dataset into _demo_ directory\n",
    "\n",
    "1. Run a docker container using the image:\n",
    "    \n",
    "    `docker run -dt -p 8888:8888 --name jupyter -v $PWD:/notebooks/my my-maskrcnn-benchmark-jupyter`\n",
    "\n",
    "1. Retrieve Jupyter notebook token using:\n",
    "    \n",
    "    `docker logs jupyter`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes our figures bigger\n",
    "pylab.rcParams['figure.figsize'] = 20, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskrcnn_benchmark.config import cfg\n",
    "from predictor import COCODemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"../configs/caffe2/e2e_mask_rcnn_R_50_FPN_1x_caffe2.yaml\"\n",
    "# update the config options with the config file\n",
    "cfg.merge_from_file(config_file)\n",
    "# manual override some options\n",
    "cfg.merge_from_list([\"MODEL.DEVICE\", \"cpu\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the `COCODemo` object. It contains a few extra options for conveniency, such as the confidence threshold for detections to be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_demo = COCODemo(\n",
    "    cfg,\n",
    "    min_image_size=800,\n",
    "    confidence_threshold=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a few helper functions for loading images from a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(url):\n",
    "    \"\"\"\n",
    "    Given an url of an image, downloads the image and\n",
    "    returns a PIL image\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    pil_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    # convert to BGR format\n",
    "    image = np.array(pil_image)[:, :, [2, 1, 0]]\n",
    "    return image\n",
    "\n",
    "def imshow(img):\n",
    "    plt.imshow(img[:, :, [2, 1, 0]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run prediction over all images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def image_iterator(paths) -> np.ndarray:\n",
    "    for path in paths:\n",
    "        image = Image.open(path)\n",
    "        image = np.array(image)[:, :, [2, 1, 0]]\n",
    "        yield image\n",
    "\n",
    "AICITY_DIR = Path('/notebooks/my/demo/data/AICity_data/train/S03/c010')\n",
    "frame_paths = AICITY_DIR.glob('frames/*')\n",
    "images = image_iterator(frame_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatme(detection):\n",
    "    return (f'{int(detection[0])},'\n",
    "            f'{int(detection[1])},'\n",
    "            f'{detection[2]:.3f},'\n",
    "            f'{detection[3]:.3f},'\n",
    "            f'{detection[4]:.3f},'\n",
    "            f'{detection[5]:.3f},'\n",
    "            f'{detection[6]:.3f},'\n",
    "            f'{int(detection[7])},'\n",
    "            f'{int(detection[8])},'\n",
    "            f'{int(detection[9])}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "output_path = Path('/notebooks/my/demo/det_mask_rcnn.txt')\n",
    "\n",
    "with output_path.open('w') as file:\n",
    "    for frame_num, image in enumerate(images, 1):\n",
    "        predictions = coco_demo.compute_prediction(image)\n",
    "        # Select only 'car' (category=3) predictions\n",
    "        cars = predictions[predictions.get_field('labels') == 3]\n",
    "\n",
    "        # Build a tensor with [labels, bbox, scores]\n",
    "        scores = cars.get_field('scores')\n",
    "        labels = cars.get_field('labels').float()\n",
    "        preds = torch.stack([\n",
    "                labels, \n",
    "                cars.bbox[:,0],\n",
    "                cars.bbox[:,1],\n",
    "                cars.bbox[:,2],\n",
    "                cars.bbox[:,3],\n",
    "                scores, \n",
    "            ], dim=1)\n",
    "\n",
    "        # Format data\n",
    "        ones = torch.ones((preds.shape[0], 1))\n",
    "        none = - ones\n",
    "        frame_num = frame_num * ones\n",
    "        data = torch.cat([frame_num, preds, - ones, -ones, -ones], dim=1)\n",
    "        lines = data.tolist()\n",
    "        \n",
    "        # Write to file\n",
    "        for detection in lines:\n",
    "            string = formatme(detection)\n",
    "            file.write(string + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
